# -*- coding: utf-8 -*-
"""Perceptron_A01749447.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivSFEzWTOXZRMIv8mqI6jmeXfL7vr9sQ
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn import datasets
import matplotlib.pyplot as plt
import numpy as np

# %matplotlib inline

N_SAMPLES = 1500
X, Y = datasets.make_blobs(n_samples=N_SAMPLES,n_features=2,centers=2,cluster_std=1.05,random_state=3)

X_TRAIN = X[:round((80*N_SAMPLES)/100)]
Y_TRAIN = Y[:round((80*N_SAMPLES)/100)]
X_TEST = X[round((80*N_SAMPLES)/100):]
Y_TEST = Y[round((80*N_SAMPLES)/100):]

def activation_func(z):
    # Funcion de activacion (funcion sigmoide)
    return 1 / (1 + np.exp(-z))

def perceptron(X, Y):
    learning_rate = 0.5
    epochs = 100
    m = X.shape[0] # cantidad de samples
    n = X.shape[1] # de entradas
    
    w_list = np.zeros((n+1,1))
    for epoch in range(epochs):
        for idx, x_i in enumerate(X):
            
            x_i = np.insert(x_i, 0, 1).reshape(-1, 1)
            y_hipotetica = activation_func(np.dot(x_i.T, w_list))
            
            if (np.squeeze(y_hipotetica) - Y[idx]) != 0:
                w_list += learning_rate*((Y[idx] - y_hipotetica)*x_i)
    return w_list

w_list = perceptron(X_TRAIN, Y_TRAIN)

n_correct = 0
for i, x_i in enumerate(X_TEST):
    x0 = x_i[1]
    x1 = x_i[0]
    z= (x0)*(w_list[0]) + (x1)*(w_list[1]) + w_list[2]
    y_pred = activation_func(z)
    if(round(y_pred[0]) == Y_TEST[i]):
        n_correct += 1
perc_correct = n_correct*100/(i+1)
print(perc_correct)